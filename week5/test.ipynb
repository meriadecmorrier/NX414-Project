{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e203cbc-2341-4c79-bd9a-03a79f912fd5",
   "metadata": {},
   "source": [
    "# Here is an example of how to use our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfffc40-245a-4ef4-a902-2a12084e4cff",
   "metadata": {},
   "source": [
    "***Please note that this is the best model we could developp ourselves based on the data driven approach. The task driven approach using ResNet50 used in Week5.ipynb gave better results however.***\n",
    "\n",
    "***The best mmodel's weights file (.pth file) is around 400MB and can be downloaded from https://we.tl/t-uhOyMznu5R \n",
    "It has to be put in the same folder as this script***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77a3044-eb9a-4e77-8c36-a73dcb8e4063",
   "metadata": {},
   "source": [
    "First, loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ecf74a-a68e-4550-8c23-c41fbf664fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.7/site-packages (4.7.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (3.8.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from h5py) (1.21.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./../')\n",
    "!{sys.executable} -m pip install gdown h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbcf3f4-148c-4a0c-ba14-aec1183fa6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1s6caFNRpyR9m7ZM6XEv_e8mcXT3_PnHS\n",
      "From (redirected): https://drive.google.com/uc?id=1s6caFNRpyR9m7ZM6XEv_e8mcXT3_PnHS&confirm=t&uuid=22ec00e7-51cc-4ae5-b279-d37dba243542\n",
      "To: /home/jupyter/NX414-Project/week5/IT_data.h5\n",
      "100%|██████████| 384M/384M [00:01<00:00, 225MB/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'IT_data.h5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from week5.utils import load_it_data, visualize_img\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gdown\n",
    "url = \"https://drive.google.com/file/d/1s6caFNRpyR9m7ZM6XEv_e8mcXT3_PnHS/view?usp=share_link\"\n",
    "output = \"IT_data.h5\"\n",
    "gdown.download(url, output, quiet=False, fuzzy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aee66ca-8822-4486-9472-06146884f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '' ## Insert the folder where the data is, if you download in the same folder as this notebook then leave it blank\n",
    "\n",
    "stimulus_train, stimulus_val, stimulus_test, objects_train, objects_val, objects_test, spikes_train, spikes_val = load_it_data(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42973282-69ed-4c55-a776-add4443f232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae1e50-ed6f-4689-926c-e876d89fceae",
   "metadata": {},
   "source": [
    "**The class corresponding to our best model architecture:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05fd1b09-a02f-4fcc-9eee-e9040acf935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch import flatten\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import time\n",
    "\n",
    "class LeNet4Fc(Module):\n",
    "\tdef __init__(self, numChannels, neurons):\n",
    "\t\t# call the parent constructor\n",
    "\t\tsuper(LeNet4Fc, self).__init__()\n",
    "\t\t# initialize first set of CONV => RELU => POOL layers\n",
    "\t\tself.conv1 = Conv2d(in_channels=numChannels, out_channels=20,\n",
    "\t\t\tkernel_size=(5, 5))\n",
    "\t\tself.relu1 = ReLU()\n",
    "\t\tself.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\t\t# initialize second set of CONV => RELU => POOL layers\n",
    "\t\tself.conv2 = Conv2d(in_channels=20, out_channels=50,\n",
    "\t\t\tkernel_size=(5, 5))\n",
    "\t\tself.relu2 = ReLU()\n",
    "\t\tself.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\t\t# 4 sets of FC => RELU layers\n",
    "\t\tself.fc1 = Linear(in_features=140450, out_features=1000)\n",
    "\t\tself.relu3 = ReLU()\n",
    "\t\tself.fc2 = Linear(in_features=1000, out_features=1000)\n",
    "\t\tself.relu4 = ReLU()\n",
    "\t\tself.fc3 = Linear(in_features=1000, out_features=500)\n",
    "\t\tself.relu5 = ReLU()\n",
    "\t\tself.fc4 = Linear(in_features=500, out_features=neurons)\n",
    "        \n",
    "\tdef forward(self, x):\n",
    "\t\t# pass the input through our first set of CONV => RELU =>\n",
    "\t\t# POOL layers\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.relu1(x)\n",
    "\t\tx = self.maxpool1(x)\n",
    "\t\t# pass the output from the previous layer through the second\n",
    "\t\t# set of CONV => RELU => POOL layers\n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = self.relu2(x)\n",
    "\t\tx = self.maxpool2(x)\n",
    "\t\t# flatten the output from the previous layer and pass it\n",
    "\t\t# through our only set of FC => RELU layers\n",
    "\t\tx = flatten(x, 1)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.relu3(x)\n",
    "\t\t#We add our two new fc layers\n",
    "\t\tx = self.fc2(x)\n",
    "\t\tx = self.relu4(x)\n",
    "\t\tx = self.fc3(x)\n",
    "\t\tx = self.relu5(x)        \n",
    "\t\t# output after the second fc layer\n",
    "\t\toutput=self.fc4(x)\n",
    "        \n",
    "\t\t# return the output predictions\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a533b5-4ffb-4a90-9633-014a3aff5877",
   "metadata": {},
   "source": [
    "**Now we load the weights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f2e99eb-2a2e-4a09-97c6-f52cf91793e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:129] . file in archive is not in a subdirectory: best_model.pth",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_13955/957938298.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNet4Fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumChannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m168\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_model.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    775\u001b[0m             \u001b[0;31m# reset back to the original position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0morig_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_torchscript_zip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m                     warnings.warn(\"'torch.load' received a zip file that looks like a TorchScript archive\"\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:129] . file in archive is not in a subdirectory: best_model.pth"
     ]
    }
   ],
   "source": [
    "model = LeNet4Fc(numChannels=3,neurons=168)\n",
    "model.load_state_dict(torch.load(\"best_model.zip\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aacb489-9f58-4fe0-9795-893488534ba0",
   "metadata": {},
   "source": [
    "Converting validation set and test sets to tensors and sending everything to the right device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f82d949-415b-40b2-8c2e-72734aa3fdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet4Fc(\n",
       "  (conv1): Conv2d(3, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=140450, out_features=1000, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (fc3): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (relu5): ReLU()\n",
       "  (fc4): Linear(in_features=500, out_features=168, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimulus_val = torch.from_numpy(stimulus_val).type(torch.FloatTensor)\n",
    "spikes_val=torch.from_numpy(spikes_val).type(torch.FloatTensor)\n",
    "\n",
    "stimulus_test=torch.from_numpy(stimulus_test).type(torch.FloatTensor)\n",
    "\n",
    "stimulus_val=stimulus_val.to(device)\n",
    "stimulus_test=stimulus_test.to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafc683a-df27-420b-a8d7-862861bb651a",
   "metadata": {},
   "source": [
    "**For example, let's use our model to predict the spikes for the validation set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65455a0e-2ee1-47cd-9d2d-13d4df339a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred_val=model(stimulus_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd542ba-e6be-4eb6-a005-0b2e50b985d8",
   "metadata": {},
   "source": [
    "**We now have all the 288x168 predictions for the validation set in the tensor named pred_val.**"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
